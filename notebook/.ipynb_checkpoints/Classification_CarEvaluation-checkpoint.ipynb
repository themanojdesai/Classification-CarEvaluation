{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred)\n",
    "    print(f1_score(y_true, y_pred, average='weighted'))\n",
    "\n",
    "def get_encode_fit(data):\n",
    "    data_encode_fit = {}\n",
    "    for col in list(data.columns):\n",
    "        data_encode_fit[col] = preprocessing.LabelEncoder()\n",
    "        data_encode_fit[col].fit(data[col])\n",
    "    return data_encode_fit\n",
    "\n",
    "def get_transform_data(data, data_encode_fit):\n",
    "    data_return = pd.DataFrame()\n",
    "    for col in list(data.columns):\n",
    "        data_return[col] = data_encode_fit[col].fit_transform(data[col])\n",
    "    return data_return\n",
    "\n",
    "def seperate_feature_label(data):\n",
    "    data_X = data[list(data.columns)[:-1]]\n",
    "    data_Y = data['label']\n",
    "    return data_X, data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '../data/train.csv'\n",
    "test_file = '../data/test.csv'\n",
    "\n",
    "train_file_data = pd.read_csv(train_file)\n",
    "test_file_data = pd.read_csv(test_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1382 entries, 0 to 1381\n",
      "Data columns (total 7 columns):\n",
      "purchasing_cost    1382 non-null object\n",
      "repair_cost        1382 non-null object\n",
      "windows            1382 non-null object\n",
      "people             1382 non-null object\n",
      "space              1382 non-null object\n",
      "safety             1382 non-null object\n",
      "label              1382 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 75.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_file_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Info : </h3> <p> From the trainig data it is evident that there are no missing values</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class : purchasing_cost , values : ['high' 'very_high' 'medium' 'low'], count : 4\n",
      "class : repair_cost , values : ['very_high' 'medium' 'high' 'low'], count : 4\n",
      "class : windows , values : ['5more' '4' '2' '3'], count : 4\n",
      "class : people , values : ['more' '4' '2'], count : 3\n",
      "class : space , values : ['medium' 'big' 'small'], count : 3\n",
      "class : safety , values : ['med' 'low' 'high'], count : 3\n",
      "class : label , values : ['unacceptable' 'acceptable' 'good' 'very_good'], count : 4\n"
     ]
    }
   ],
   "source": [
    "for i in train_file_data.columns:\n",
    "    print(f'class : {i} , values : {train_file_data[i].unique()}, count : {train_file_data[i].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Info : </h3> <p>From the above info, all features are catagorical </p>\n",
    "<h2>Action: </h2> <p> All the features and labels are catagorical, Hence converting to numerical. Using LabelEncoder for converting catagorical data to numerical data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_fit = get_encode_fit(train_file_data)\n",
    "train_transform_data = get_transform_data(train_file_data, train_encoded_fit)\n",
    "test_transform_data = get_transform_data(test_file_data, train_encoded_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f91a913a6a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAEHVJREFUeJzt3X2sZVV9xvHvIwMivvF2pTiDDq0TW2ptgRuKkmgVa4W2DjVgNCoTSzJNahVL00r7R2k1NpqqqMSQTAQdWqISsIUaopkgYrQFnUHkbbRMqGWmIHMtb6Kxiv76x1k3XIeROQvuPfueme8nOTl7r732md/sEJ7Za++9dqoKSZLG9ZShC5AkTReDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSlxVDF7AUDj/88Fq9evXQZUjSVNmyZcv3qmpmT/32yuBYvXo1mzdvHroMSZoqSf57nH5LNlSV5OIkO5PcuqDt0CSbktzRvg9p7Uny0STbktyc5LgF+6xr/e9Ism6p6pUkjWcpr3F8EnjNLm3nAtdU1RrgmrYOcAqwpn3WAxfCKGiA84DfBk4AzpsPG0nSMJYsOKrqy8B9uzSvBTa25Y3AaQvaL6mR64GDkxwJ/B6wqaruq6r7gU08NowkSRM06buqjqiqewDa93Na+0pg+4J+O1rbL2p/jCTrk2xOsnlubm7RC5ckjSyX23Gzm7Z6nPbHNlZtqKrZqpqdmdnjTQGSpCdo0sFxbxuCon3vbO07gKMW9FsF3P047ZKkgUw6OK4C5u+MWgdcuaD9zHZ31YnAg20o6wvAq5Mc0i6Kv7q1SZIGsmTPcST5FPA7wOFJdjC6O+p9wGVJzgLuAs5o3a8GTgW2AT8E3gpQVfcleQ/w9dbv3VW16wV3SdIEZW985/js7Gz5AKAk9Umypapm99Rvr3xyXJpmJ11w0tAlLBtffftXhy5Bu7Fc7qqSJE0Jg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldBgmOJH+e5LYktyb5VJIDkxyd5IYkdyT5TJIDWt+ntvVtbfvqIWqWJI1MPDiSrATeAcxW1YuA/YA3AO8Hzq+qNcD9wFltl7OA+6vqBcD5rZ8kaSBDDVWtAJ6WZAVwEHAP8Erg8rZ9I3BaW17b1mnbT06SCdYqSVpg4sFRVf8DfAC4i1FgPAhsAR6oqkdatx3Ayra8Etje9n2k9T9skjVLkh41xFDVIYzOIo4Gngs8HThlN11rfpfH2bbwd9cn2Zxk89zc3GKVK0naxRBDVa8C/quq5qrqJ8BngZcCB7ehK4BVwN1teQdwFEDb/mzgvl1/tKo2VNVsVc3OzMws9d9BkvZZQwTHXcCJSQ5q1ypOBm4HrgVOb33WAVe25avaOm37F6vqMWcckqTJGOIaxw2MLnLfCNzSatgAvAs4J8k2RtcwLmq7XAQc1trPAc6ddM2SpEet2HOXxVdV5wHn7dJ8J3DCbvr+CDhjEnVJkvbMJ8clSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVKXQYIjycFJLk/yrSRbk7wkyaFJNiW5o30f0vomyUeTbEtyc5LjhqhZkjQy1BnHR4DPV9WvAr8JbAXOBa6pqjXANW0d4BRgTfusBy6cfLmSpHkTD44kzwJeBlwEUFU/rqoHgLXAxtZtI3BaW14LXFIj1wMHJzlywmVLkpohzjh+GZgDPpHkG0k+nuTpwBFVdQ9A+35O678S2L5g/x2t7eckWZ9kc5LNc3NzS/s3kKR92BDBsQI4Driwqo4FfsCjw1K7k9201WMaqjZU1WxVzc7MzCxOpZKkxxgiOHYAO6rqhrZ+OaMguXd+CKp971zQ/6gF+68C7p5QrZKkXUw8OKrqu8D2JC9sTScDtwNXAeta2zrgyrZ8FXBmu7vqRODB+SEtSdLkrRjoz307cGmSA4A7gbcyCrHLkpwF3AWc0fpeDZwKbAN+2PpKkgYySHBU1U3A7G42nbybvgW8bcmLkiSNxSfHJUldxgqOJNeM0yZJ2vs97lBVkgOBg4DD2xQg87fGPgt47hLXJklahvZ0jeNPgHcyCoktPBocDwEfW8K6JEnL1OMGR1V9BPhIkrdX1QUTqkmStIyNdVdVVV2Q5KXA6oX7VNUlS1SXJGmZGis4kvwT8CvATcBPW3MBBock7WPGfY5jFjimPVMhSdqHjfscx63ALy1lIZKk6TDuGcfhwO1Jvgb833xjVb12SaqSJC1b4wbH3y1lEZKk6THuXVXXLXUhkqTpMO5dVd/n0ZcnHQDsD/ygqp61VIVJkpancc84nrlwPclpwAlLUpEkaVl7QrPjVtW/Aq9c5FokSVNg3KGq1y1YfQqj5zp8pkOS9kHj3lX1hwuWHwG+A6xd9GokScveuNc4fF2rJAkY/0VOq5L8S5KdSe5NckWSVUtdnCRp+Rn34vgngKsYvZdjJfBvrU2StI8ZNzhmquoTVfVI+3wSmFnCuiRJy9S4wfG9JG9Osl/7vBn436UsTJK0PI0bHH8MvB74LnAPcDrgBXNJ2geNezvue4B1VXU/QJJDgQ8wChRJ0j5k3DOOF8+HBkBV3QccuzQlSZKWs3GD4ylJDplfaWcc456tSJL2IuP+z/+DwL8nuZzRVCOvB967ZFVJkpatcZ8cvyTJZkYTGwZ4XVXdvqSVSZKWpbGHm1pQGBaStI97QtOqS5L2XQaHJKmLwSFJ6mJwSJK6DBYcbc6rbyT5XFs/OskNSe5I8pkkB7T2p7b1bW376qFqliQNe8ZxNrB1wfr7gfOrag1wP3BWaz8LuL+qXgCc3/pJkgYySHC0l0D9PvDxth5Gz4hc3rpsBE5ry2vbOm37ya2/JGkAQ51xfBj4K+Bnbf0w4IGqeqSt72D0wija93aAtv3B1l+SNICJB0eSPwB2VtWWhc276VpjbFv4u+uTbE6yeW5ubhEqlSTtzhBnHCcBr03yHeDTjIaoPgwcnGT+SfZVwN1teQdwFEDb/mzgvl1/tKo2VNVsVc3OzPhyQklaKhMPjqr666paVVWrgTcAX6yqNwHXMnpBFMA64Mq2fFVbp23/YlU95oxDkjQZy+k5jncB5yTZxugaxkWt/SLgsNZ+DnDuQPVJkhj4nRpV9SXgS235TuCE3fT5EXDGRAuTJP1Cy+mMQ5I0BQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1GfRFTkM6/i8vGbqEZWPLP545dAmSpohnHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4TD44kRyW5NsnWJLclObu1H5pkU5I72vchrT1JPppkW5Kbkxw36ZolSY8a4ozjEeAvqurXgBOBtyU5BjgXuKaq1gDXtHWAU4A17bMeuHDyJUuS5k08OKrqnqq6sS1/H9gKrATWAhtbt43AaW15LXBJjVwPHJzkyAmXLUlqBr3GkWQ1cCxwA3BEVd0Do3ABntO6rQS2L9htR2vb9bfWJ9mcZPPc3NxSli1J+7TBgiPJM4ArgHdW1UOP13U3bfWYhqoNVTVbVbMzMzOLVaYkaReDBEeS/RmFxqVV9dnWfO/8EFT73tnadwBHLdh9FXD3pGqVJP28Ie6qCnARsLWqPrRg01XAura8DrhyQfuZ7e6qE4EH54e0JEmTt2KAP/Mk4C3ALUluam1/A7wPuCzJWcBdwBlt29XAqcA24IfAWydbriRpoYkHR1V9hd1ftwA4eTf9C3jbkhYlSRqbT45LkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkrqsGLoATb+73v0bQ5ewbDzvb28ZugTt4rqXvXzoEpaNl3/5ukX5Hc84JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1GVqgiPJa5J8O8m2JOcOXY8k7aumIjiS7Ad8DDgFOAZ4Y5Jjhq1KkvZNUxEcwAnAtqq6s6p+DHwaWDtwTZK0T5qW4FgJbF+wvqO1SZImbFrmqspu2urnOiTrgfVt9eEk317yqp68w4HvDV1EPrBu6BIWy/DH87zd/ac6tQY/nnnHXnM8Bz+WAGSPx/P54/zMtATHDuCoBeurgLsXdqiqDcCGSRb1ZCXZXFWzQ9ext/B4Li6P5+LZ247ltAxVfR1Yk+ToJAcAbwCuGrgmSdonTcUZR1U9kuTPgC8A+wEXV9VtA5clSfukqQgOgKq6Grh66DoW2VQNrU0Bj+fi8ngunr3qWKaq9txLkqRmWq5xSJKWCYNjIE6hsniSXJxkZ5Jbh65l2iU5Ksm1SbYmuS3J2UPXNM2SHJjka0m+2Y7n3w9d02JwqGoAbQqV/wR+l9Gtxl8H3lhVtw9a2JRK8jLgYeCSqnrR0PVMsyRHAkdW1Y1JnglsAU7zv80nJkmAp1fVw0n2B74CnF1V1w9c2pPiGccwnEJlEVXVl4H7hq5jb1BV91TVjW35+8BWnKXhCauRh9vq/u0z9f9aNziG4RQqWvaSrAaOBW4YtpLplmS/JDcBO4FNVTX1x9PgGMYep1CRhpTkGcAVwDur6qGh65lmVfXTqvotRjNenJBk6odTDY5h7HEKFWkobSz+CuDSqvrs0PXsLarqAeBLwGsGLuVJMziG4RQqWpbaxdyLgK1V9aGh65l2SWaSHNyWnwa8CvjWsFU9eQbHAKrqEWB+CpWtwGVOofLEJfkU8B/AC5PsSHLW0DVNsZOAtwCvTHJT+5w6dFFT7Ejg2iQ3M/oH46aq+tzANT1p3o4rSeriGYckqYvBIUnqYnBIkroYHJKkLgaHJKmLwSEtgiQP72H76t7Ze5N8MsnpT64yafEZHJKkLgaHtIiSPCPJNUluTHJLkoWzHq9IsjHJzUkuT3JQ2+f4JNcl2ZLkC21qc2nZMjikxfUj4I+q6jjgFcAH2zQeAC8ENlTVi4GHgD9t80JdAJxeVccDFwPvHaBuaWwrhi5A2ssE+If2cqmfMZou/4i2bXtVfbUt/zPwDuDzwIuATS1f9gPumWjFUieDQ1pcbwJmgOOr6idJvgMc2LbtOr9PMQqa26rqJZMrUXpyHKqSFtezgZ0tNF4BPH/BtuclmQ+INzJ6jei3gZn59iT7J/n1iVYsdTI4pMV1KTCbZDOjs4+FU2hvBda1mVIPBS5srw4+HXh/km8CNwEvnXDNUhdnx5UkdfGMQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSl/8Hh07u04gaZ7kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train_transform_data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Info : </h3> <p>From the above plot its is clear that, lables are unbalanced </p>\n",
    "<h2>Action: </h2> <p>For unbalanced labels, 'accuracy' is not a good matrix for evaluation. Hence choosing f1 score as evalutaion parameter </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Train, Test data from train_file_data\n",
    "train, test = train_test_split(train_transform_data, test_size=0.3, random_state = 42)\n",
    "\n",
    "data_train_X, data_train_Y = seperate_feature_label(train)\n",
    "data_test_X, data_test_Y = seperate_feature_label(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) SVM - Linear kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_Linear_kernal_score : 0.6477715839308782\n"
     ]
    }
   ],
   "source": [
    "#Linear classifier\n",
    "clf = svm.SVC(kernel='linear', C=1,random_state = 42).fit(data_train_X, data_train_Y)\n",
    "scores = cross_val_score(clf, data_train_X, data_train_Y, cv=5, scoring='f1_weighted')\n",
    "print(f'SVM_Linear_kernal_score : {scores.mean()}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Info: </h3> <p>F1 score for svm linear kernal is not good. Hence trying 'rbf' kernal </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) SVM - RBF kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_RBF_kernal_score : 0.8299643256662336\n"
     ]
    }
   ],
   "source": [
    "#Linear classifier\n",
    "clf = svm.SVC(kernel='rbf', C=1,random_state = 42).fit(data_train_X, data_train_Y)\n",
    "scores = cross_val_score(clf, data_train_X, data_train_Y, cv=5, scoring='f1_weighted')\n",
    "print(f'SVM_RBF_kernal_score : {scores.mean()}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Info: </h3> <p>F1 score for svm RBF kernal is better and got improved. Hence trying 'rbf' with grid search with different c values</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) SVM - RBF kernal - GridSearch with different c values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - RBF - best model : {'C': 50}\n",
      "\n",
      "0.830 (+/-0.040) for {'C': 1}\n",
      "0.958 (+/-0.016) for {'C': 5}\n",
      "0.974 (+/-0.029) for {'C': 10}\n",
      "0.980 (+/-0.017) for {'C': 20}\n",
      "0.981 (+/-0.016) for {'C': 50}\n",
      "0.979 (+/-0.015) for {'C': 100}\n",
      "\n",
      "SVM - RBF - f1 score : 0.9712510903508856 \n",
      "SVM - RBF - Accuracy : 0.9710843373493976 \n"
     ]
    }
   ],
   "source": [
    "parameters = {'C':[1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "svc = svm.SVC(random_state=42, kernel='rbf')\n",
    "clf = GridSearchCV(svc, parameters, cv=5, scoring='f1_weighted')\n",
    "\n",
    "clf.fit(data_train_X, data_train_Y)\n",
    "print('SVM - RBF - best model : ' + str(clf.best_params_))\n",
    "\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "print(\"\")\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "    \n",
    "y_pred = clf.predict(data_test_X)    \n",
    "\n",
    "print(\"\")\n",
    "print(f\"SVM - RBF - f1 score : {f1_score(data_test_Y, y_pred, average='weighted')} \" )\n",
    "print(f\"SVM - RBF - Accuracy : {accuracy_score(data_test_Y, y_pred)} \" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Info: </h3> <p>F1 score got increased to 97.12% . Should try other classifier and choose the best among them</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Decision Tree classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree_score : 0.9603153222337145\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=42).fit(data_train_X, data_train_Y)\n",
    "scores = cross_val_score(clf, data_train_X, data_train_Y, cv=5, scoring='f1_weighted')\n",
    "print(f'DecisionTree_score : {scores.mean()}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Info: </h3> <p>F1 score is 96%. This can be increased by using different combination of hyperparameters</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Decision Tree classifier - GridSearch  , Combination of max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - best model : {'max_depth': 14}\n",
      "\n",
      "0.582 (+/-0.009) for {'max_depth': 1}\n",
      "0.743 (+/-0.039) for {'max_depth': 2}\n",
      "0.773 (+/-0.031) for {'max_depth': 3}\n",
      "0.804 (+/-0.026) for {'max_depth': 4}\n",
      "0.855 (+/-0.039) for {'max_depth': 5}\n",
      "0.873 (+/-0.034) for {'max_depth': 6}\n",
      "0.913 (+/-0.040) for {'max_depth': 7}\n",
      "0.934 (+/-0.027) for {'max_depth': 8}\n",
      "0.937 (+/-0.038) for {'max_depth': 9}\n",
      "0.957 (+/-0.030) for {'max_depth': 10}\n",
      "0.960 (+/-0.036) for {'max_depth': 11}\n",
      "0.955 (+/-0.029) for {'max_depth': 12}\n",
      "0.958 (+/-0.036) for {'max_depth': 13}\n",
      "0.960 (+/-0.031) for {'max_depth': 14}\n",
      "0.960 (+/-0.031) for {'max_depth': 15}\n",
      "0.960 (+/-0.031) for {'max_depth': 16}\n",
      "0.960 (+/-0.031) for {'max_depth': 17}\n",
      "0.960 (+/-0.031) for {'max_depth': 18}\n",
      "0.960 (+/-0.031) for {'max_depth': 19}\n",
      "\n",
      "Decision Tree - f1 score : 0.9569597131781012 \n",
      "Decision Tree - Accuracy : 0.9566265060240964 \n"
     ]
    }
   ],
   "source": [
    "parameters={'max_depth': range(1,20,1)}\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf = GridSearchCV(dtc, parameters, cv=5, scoring='f1_weighted')\n",
    "clf.fit(data_train_X, data_train_Y)\n",
    "print('Decision Tree - best model : ' + str(clf.best_params_))\n",
    "\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "print(\"\")\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "            % (mean, std * 2, params))\n",
    "    \n",
    "y_pred = clf.predict(data_test_X)    \n",
    "\n",
    "print(\"\")\n",
    "print(f\"Decision Tree - f1 score : {f1_score(data_test_Y, y_pred, average='weighted')} \" )\n",
    "print(f\"Decision Tree - Accuracy : {accuracy_score(data_test_Y, y_pred)} \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Info: </h3> <p>F1 score got reduced to 95%. But, using different combination helps us to find the better model</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Score : 0.9154969213901257\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=42).fit(data_train_X, data_train_Y)\n",
    "scores = cross_val_score(clf, data_train_X, data_train_Y, cv=5, scoring='f1_weighted')\n",
    "print(f'Random Forest Score : {scores.mean()}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Info: </h3> <p>F1 score is 91%. This can be increased by using different combination of hyperparameters</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) RandomForest Classifier - combination of max_depth and number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - best model : {'max_depth': 15, 'n_estimators': 50}\n",
      "Random Forest - f1 score : 0.9555224108807716 \n",
      "Random Forest - Accuracy : 0.9566265060240964 \n"
     ]
    }
   ],
   "source": [
    "parameters={'max_depth': range(4,20,1),'n_estimators': range(10,100,5)}\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "clf = GridSearchCV(rfc, parameters, cv=5, scoring='f1_weighted')\n",
    "clf.fit(data_train_X, data_train_Y)\n",
    "\n",
    "print('Random Forest - best model : ' + str(clf.best_params_))\n",
    "\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "y_pred = clf.predict(data_test_X)    \n",
    "\n",
    "print(f\"Random Forest - f1 score : {f1_score(data_test_Y, y_pred, average='weighted')} \" )\n",
    "print(f\"Random Forest - Accuracy : {accuracy_score(data_test_Y, y_pred)} \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Info: </h3> <p>F1 score is got improved to 95.5%. This can be increased further by improving the selection of hyperparameter</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) RandomForest Classifier - Enhancement by trying different criterion, max_features and max_leaf node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - best model : {'criterion': 'entropy', 'max_depth': 20, 'max_features': 6, 'max_leaf_nodes': None}\n",
      "Random Forest - f1 score : 0.9762270618960779 \n",
      "Random Forest - Accuracy : 0.9759036144578314 \n"
     ]
    }
   ],
   "source": [
    "parameters={'criterion':['gini','entropy'],\n",
    "            'max_depth':[2,5,10,20],\n",
    "            'max_features':[2,4,6,'auto'],\n",
    "           'max_leaf_nodes':[2,3,None],}\n",
    "rfc = RandomForestClassifier(random_state=42, n_estimators=50)\n",
    "clf = GridSearchCV(rfc, parameters, cv=5, scoring='f1_weighted')\n",
    "clf.fit(data_train_X, data_train_Y)\n",
    "print('Random Forest - best model : ' + str(clf.best_params_))\n",
    "\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "y_pred = clf.predict(data_test_X)    \n",
    "\n",
    "print(f\"Random Forest - f1 score : {f1_score(data_test_Y, y_pred, average='weighted')} \" )\n",
    "print(f\"Random Forest - Accuracy : {accuracy_score(data_test_Y, y_pred)} \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Info: </h3> <p>F1 score is got improved to 97.6%. Using this combination for futher improvement</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Ensemble model using best of above classifiers.\n",
    "\n",
    "<h3>Note : </h3> This ensemble avoids overfitting of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble  - f1 score : 0.9715673705279497 \n",
      "Ensemble  - Accuracy : 0.9710843373493976 \n"
     ]
    }
   ],
   "source": [
    "#Ensemble of all three classifiers\n",
    "clf1 = svm.SVC(C=50,kernel='rbf', random_state=42)\n",
    "\n",
    "clf2 = tree.DecisionTreeClassifier(max_depth=14, random_state=42)\n",
    "\n",
    "clf3 = RandomForestClassifier(criterion='entropy',max_depth=20, \n",
    "                              max_features=6,max_leaf_nodes=None,\n",
    "                              n_estimators=50, random_state=42)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('svm', clf1), ('dtc', clf2), ('rfc', clf3)], voting='hard')\n",
    "\n",
    "eclf.fit(data_train_X, data_train_Y)\n",
    "y_pred = eclf.predict(data_test_X)    \n",
    "\n",
    "\n",
    "print(f\"Ensemble  - f1 score : {f1_score(data_test_Y, y_pred, average='weighted')} \" )\n",
    "print(f\"Ensemble  - Accuracy : {accuracy_score(data_test_Y, y_pred)} \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Info: </h3> This model shall be used for production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub_pred = eclf.predict(test_transform_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_pd = test_transform_data\n",
    "submission_pd['label'] = y_sub_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_data(data, data_encode_fit):\n",
    "    data_return = pd.DataFrame()\n",
    "    for col in list(data.columns):\n",
    "        data_return[col] = data_encode_fit[col].inverse_transform(data[col])\n",
    "    return data_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set = get_original_data(submission_pd, train_encoded_fit)\n",
    "submission_set = submission_set.reset_index()\n",
    "submission_set = submission_set[['index', 'label']]\n",
    "submission_set = submission_set.set_index('index')\n",
    "submission_set.to_csv('../output/submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
